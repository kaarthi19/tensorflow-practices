# -*- coding: utf-8 -*-
"""RNN Shapes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16xtVTgJmu2USuIV7J9VHX6u1qoyyHbZk
"""

!pip install -q tensorflow==2.1.0
import tensorflow as tf
print(tf.__version__)

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from tensorflow.keras.layers import Input, SimpleRNN, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD, Adam

#remember all of these
#N = number of samples in the dataset
#T = sequence length
#D = number of input features
#M = number of hidden units
#K = number of output units

#synthetic data creation
N = 1
T = 10
D = 3
K = 2
X = np.random.randn(N, T, D)

#make a RNN
M = 5
i = Input(shape=(T, D))
x = SimpleRNN(M)(i)
x = Dense(K)(x)

model = Model(i, x)

#make a random prediction

Yhat = model.predict(X)
print(Yhat)

#model summary
model.summary()

#check the weight since we dont know

model.layers[1].get_weights()

Wx, Wh, bh = model.layers[1].get_weights()
Wo, bo = model.layers[2].get_weights()

#calculations made in the RNN layer
h_last = np.zeros(M) # initial hidden state
x = X[0] # the one and only sample
Yhats = [] # where we store the outputs

for t in range(T):
  h = np.tanh(x[t].dot(Wx) + h_last.dot(Wh) + bh)
  y = h.dot(Wo) + bo # we only care about this value on the last iteration
  Yhats.append(y)
  
  # important: assign h to h_last
  h_last = h

# print the final output
print(Yhats[-1])